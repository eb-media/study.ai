import streamlit as st
import json, os
from openai import OpenAI
from dotenv import load_dotenv

# ==========================
# ğŸ”‘ SETUP
# ==========================
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

st.set_page_config(page_title="Arabic Study Assistant", layout="centered")

# ==========================
# ğŸ“š Load book data
# ==========================
with open("data/arabic_book_text.txt", "r", encoding="utf-8") as f:
    book_text = f.read()
with open("data/embeddings.json", "r", encoding="utf-8") as f:
    embeddings = json.load(f)

chapters = {
    "ğŸ“– Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": [
        "Ø¥Ø±Ø§Ø¯Ø© Ø§Ù„ØªØºÙŠÙŠØ±", "Ø£Ø¨Ùˆ Ø§Ù„Ø±ÙŠØ­Ø§Ù† Ø§Ù„Ø¨ÙŠØ±ÙˆÙ†ÙŠ", "Ø§Ù„Ù‚Ø¯Ø³ Ù…Ø¯ÙŠÙ†Ø© Ø¹Ø±Ø¨ÙŠØ© Ø¥Ø³Ù„Ø§Ù…ÙŠØ©",
        "Ø§Ù„Ø¹Ù„Ù… ÙÙŠ Ø§Ù„Ø¥Ø³Ù„Ø§Ù…", "Ù‚ÙŠÙ… Ø¥Ù†Ø³Ø§Ù†ÙŠØ©"
    ],
    "âœï¸ Ø§Ù„Ø£Ø¯Ø¨ ÙˆØ§Ù„Ù†ØµÙˆØµ": [
        "Ù…Ø¯Ø±Ø³Ø© Ø§Ù„Ø¥Ø­ÙŠØ§Ø¡ ÙˆØ§Ù„Ø¨Ø¹Ø«", "Ø£Ø­Ù…Ø¯ Ø´ÙˆÙ‚ÙŠ", "Ø§Ù„Ù…Ø¯Ø§Ø±Ø³ Ø§Ù„Ø±ÙˆÙ…Ø§Ù†ØªÙŠÙƒÙŠØ©", "Ø§Ù„Ù…Ù‚Ø§Ù„",
        "Ø§Ù„Ù‚ØµØ© Ø§Ù„Ù‚ØµÙŠØ±Ø©", "Ø§Ù„ØªÙ…Ø«ÙŠÙ„ÙŠØ©"
    ],
    "ğŸ¨ Ø§Ù„Ø¨Ù„Ø§ØºØ©": ["Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø´Ø¹Ø±ÙŠØ©", "Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„ÙÙ†ÙŠØ©"],
    "ğŸ§  Ø§Ù„ØªØ¯Ø±ÙŠØ¨Ø§Øª Ø§Ù„Ù„ØºÙˆÙŠØ©": [
        "Ø§Ù„Ù†Ø·Ù‚ ÙˆØ§Ù„Ø¥Ù…Ù„Ø§Ø¡", "Ø§Ù„Ø£Ø¨Ù†ÙŠØ©", "Ø§Ù„ØªØ±Ø§ÙƒÙŠØ¨", "Ø¥Ø¹Ø±Ø§Ø¨ Ø§Ù„Ø§Ø³Ù…",
        "Ø¥Ø¹Ø±Ø§Ø¨ Ø§Ù„ÙØ¹Ù„", "Ø§Ù„Ø£Ø¯ÙˆØ§Øª", "Ø§Ù„Ù…Ù…Ù†ÙˆØ¹ Ù…Ù† Ø§Ù„ØµØ±Ù"
    ],
}

# ==========================
# ğŸ’¬ Chat Interface
# ==========================
st.title("ğŸ§  Arabic Study Assistant")
st.caption("Chat with your Arabic book â€” ask questions, get summaries or generate quizzes.")

st.sidebar.header("ğŸ“š Choose Chapter")
chapter = st.sidebar.selectbox("Main Section:", list(chapters.keys()))
unit = st.sidebar.selectbox("Unit:", chapters[chapter])

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display previous chat history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# User input
user_input = st.chat_input("Ask something about this unit...")

if user_input:
    # Add user message to session state
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # Display "thinking..." before the AI responds
    with st.chat_message("assistant"):
        thinking_placeholder = st.empty()
        thinking_placeholder.markdown("ğŸ¤” **Thinking...**")

        try:
            # Generate response using OpenAI API
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": f"You are a helpful Arabic study assistant. Context: chapter '{chapter}', unit '{unit}'."},
                    *st.session_state.messages
                ]
            )
            answer = response.choices[0].message.content

            # Replace "thinking..." with final answer
            thinking_placeholder.markdown(answer)

            # Save AI message to chat history
            st.session_state.messages.append({"role": "assistant", "content": answer})

        except Exception as e:
            thinking_placeholder.markdown(f"âš ï¸ Error: {e}")

